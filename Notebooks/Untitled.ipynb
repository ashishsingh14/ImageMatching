{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.misc import imread\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_categories = {\"bras\": \"panties\", \"panties\": \"bras\"}\n",
    "categories = [\"bras\", \"panties\"]\n",
    "data_path = \"/Users/asingh/Documents/Learning/Projects/Image_Matching/Data/\"\n",
    "output_path = \"/Users/asingh/Documents/Learning/Projects/Image_Matching/Notebooks/Output/\"\n",
    "image_path = os.path.join(data_path, \"images\")\n",
    "features_path = os.path.join(data_path, \"features_kaze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extractor\n",
    "def extract_features(image_path, vector_size=32):\n",
    "    image = imread(image_path, mode=\"RGB\")\n",
    "    try:\n",
    "        # Using KAZE, cause SIFT, ORB and other was moved to additional module\n",
    "        # which is adding addtional pain during install\n",
    "        alg = cv2.KAZE_create()\n",
    "        # Dinding image keypoints\n",
    "        kps = alg.detect(image)\n",
    "        # Getting first 32 of them. \n",
    "        # Number of keypoints is varies depend on image size and color pallet\n",
    "        # Sorting them based on keypoint response value(bigger is better)\n",
    "        kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n",
    "        # computing descriptors vector\n",
    "        kps, dsc = alg.compute(image, kps)\n",
    "        # Flatten all of them in one big vector - our feature vector\n",
    "        dsc = dsc.flatten()\n",
    "        # Making descriptor of same size\n",
    "        # Descriptor vector size is 64\n",
    "        needed_size = (vector_size * 64)\n",
    "        if dsc.size < needed_size:\n",
    "            # if we have less the 32 descriptors then just adding zeros at the\n",
    "            # end of our feature vector\n",
    "            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "    except cv2.error as e:\n",
    "        print('Error: ', e)\n",
    "        return None\n",
    "\n",
    "    return dsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(categories):\n",
    "    for category in categories:\n",
    "        category_images_path = os.path.join(image_path, category)\n",
    "        files = [os.path.join(category_images_path, file) for file in os.listdir(category_images_path)]\n",
    "\n",
    "        result = {}\n",
    "        for f in files:\n",
    "            name = f.split('/')[-1].split(\".\")[0]\n",
    "            try:\n",
    "                result[name] = extract_features(f)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "        # saving all our feature vectors in pickled file\n",
    "        pickled_db_path = os.path.join(features_path, category + \".pck\")\n",
    "        with open(pickled_db_path, 'wb') as fp:\n",
    "            pickle.dump(result, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asingh/Documents/virtualenvironments/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8h 5min 52s, sys: 1h 7min 55s, total: 9h 13min 48s\n",
      "Wall time: 7h 32min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "feature_extractor(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_path, \"bras\" + \".pck\"), \"rb\") as f:\n",
    "    bras_features = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(features_path, \"panties\" + \".pck\"), \"rb\") as f:\n",
    "    panties_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = {\"bras\": bras_features, \"panties\": panties_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1699, 3314)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bras_features), len(panties_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00503823, -0.04584654,  0.01468258, ..., -0.00024455,\n",
       "        0.00077621,  0.00025226], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bras_features['224438_0000006395']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCosineSimilarity(feature1, feature2):\n",
    "    \"\"\"\n",
    "    Fucntion to get the cos similarity between two vectors\n",
    "    :param feature1:\n",
    "    :param feature2:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return np.dot(feature1, feature2) / (np.linalg.norm(feature1) * np.linalg.norm(feature2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(features1, features2, category, output_path, top_matches_count=15):\n",
    "    output_matches = {}\n",
    "    for feature_name1, feature1 in features1.items():\n",
    "        sku1, image_variation_name1 = feature_name1.split(\"_\")\n",
    "        if sku1 not in output_matches:\n",
    "            output_matches[sku1] = {}\n",
    "        output_matches[sku1][image_variation_name1] = []\n",
    "        matches = []\n",
    "        for feature_name2, feature2 in features2.items():\n",
    "            sku2, image_variation_name2 = feature_name2.split(\"_\")\n",
    "            if feature_name1 != feature_name2:\n",
    "                similarity = round(findCosineSimilarity(feature1, feature2), 4)\n",
    "                matches.append((sku2, image_variation_name2, similarity))\n",
    "        topmatches = sorted(matches, key=lambda x: x[2], reverse=True)[:top_matches_count]\n",
    "        topmatches_formatted = [{\"sku\": sku2, \"color_code\": image_variation_name2,\n",
    "                                 \"similarity_score\": str(score)} for sku2, image_variation_name2, score in topmatches]\n",
    "        output_matches[sku1][image_variation_name1].extend(topmatches_formatted)\n",
    "        \n",
    "    try:\n",
    "        with open(output_path + \"{}.json\".format(category), \"w\") as output_file_object:\n",
    "            output_file_object.write(json.dumps(output_matches))\n",
    "    except Exception as e:\n",
    "        print(\"Error in writing the image matches: {}\".format(str(e)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for the category : bras\n",
      "Computing for the category : panties\n"
     ]
    }
   ],
   "source": [
    "for c in categories:\n",
    "    print(\"Computing for the category : {}\".format(c))\n",
    "    calculate_similarity(all_features[c], all_features[mapping_categories[c]], c, \n",
    "                         output_path, top_matches_count=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/asingh/Documents/Learning/Projects/Image_Matching/Notebooks/Output/bras.json'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path + \"bras.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3], [3,4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 3, 4, 5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file for file in os.listdir(\"/Users/asingh/Documents/Learning/Projects/Image_Matching/Data/images/bras/\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asingh/Documents/virtualenvironments/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.28 s, sys: 758 ms, total: 6.04 s\n",
      "Wall time: 2.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = {}\n",
    "result[\"102472_0000012202\"] = extract_features(\"/Users/asingh/Documents/Learning/Projects/Image_Matching/Data/images/bras/102472_0000012202.jpg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/asingh/temp.pck\", \"wb\") as f:\n",
    "    pickle.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/asingh/temp.pck\", \"rb\") as f:\n",
    "    t = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result[\"102472_0000012202\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t[\"102472_0000012202\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Matcher(object):\n",
    "\n",
    "    def __init__(self, pickled_db_path=\"features.pck\"):\n",
    "        with open(pickled_db_path) as fp:\n",
    "            self.data = pickle.load(fp)\n",
    "        self.names = []\n",
    "        self.matrix = []\n",
    "        for k, v in self.data.iteritems():\n",
    "            self.names.append(k)\n",
    "            self.matrix.append(v)\n",
    "        self.matrix = np.array(self.matrix)\n",
    "        self.names = np.array(self.names)\n",
    "\n",
    "    def cos_cdist(self, vector):\n",
    "        # getting cosine distance between search image and images database\n",
    "        v = vector.reshape(1, -1)\n",
    "        return scipy.spatial.distance.cdist(self.matrix, v, 'cosine').reshape(-1)\n",
    "\n",
    "    def match(self, image_path, topn=5):\n",
    "        features = extract_features(image_path)\n",
    "        img_distances = self.cos_cdist(features)\n",
    "        # getting top 5 records\n",
    "        nearest_ids = np.argsort(img_distances)[:topn].tolist()\n",
    "        nearest_img_paths = self.names[nearest_ids].tolist()\n",
    "\n",
    "        return nearest_img_paths, img_distances[nearest_ids].tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
